{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXVcp95kNzaM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.applications import VGG16\n",
        "from keras.optimizers import Adam\n",
        "import pickle\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e6K4_4QOz2Y",
        "outputId": "cc56fcce-2fea-431e-a7d2-2f4e57bbcbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DataFrame which includes the path and label\n",
        "df_data = pd.read_csv('/content/drive/MyDrive/AML/Challenge1/dataset/train.csv')  # Adjust path as needed\n",
        "data_dir = '/content/drive/MyDrive/AML/Challenge1/dataset/train/train/'\n",
        "\n",
        "\n",
        "\n",
        "df_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOPRafwbN7Se",
        "outputId": "1ff64090-d4e1-4ad1-ae24-2dba4dace7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17500, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n"
      ],
      "metadata": {
        "id": "DVjEKYJ7ezA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load the images and labels\n",
        "with open('/content/drive/MyDrive/AML/Challenge1/images.pickle', 'rb') as f:\n",
        "    images = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/AML/Challenge1/labels.pickle', 'rb') as f:\n",
        "    labels = pickle.load(f)\n",
        "\n",
        "# Assume labels is a list that has been previously loaded or defined\n",
        "# labels = [...]\n",
        "\n",
        "# Create stratified training and temporary sets (validation + test)\n",
        "train_indices, temp_indices, _, _ = train_test_split(\n",
        "    np.arange(len(images)),  # indices of the images\n",
        "    labels,                  # corresponding labels\n",
        "    test_size=0.3,           # 30% for validation + test\n",
        "    random_state=42,         # for reproducibility\n",
        "    stratify=labels          # stratify by labels\n",
        ")\n",
        "\n",
        "# Split the temporary set into validation and test sets\n",
        "val_indices, test_indices, _, _ = train_test_split(\n",
        "    temp_indices,\n",
        "    [labels[i] for i in temp_indices],  # extract labels for stratification\n",
        "    test_size=0.5,                      # split the 30% into 15% validation and 15% test\n",
        "    random_state=42,                    # for reproducibility\n",
        "    stratify=[labels[i] for i in temp_indices]  # stratify by labels\n",
        ")\n",
        "\n",
        "# Use indices to select images for each dataset\n",
        "train_images = [images[i] for i in train_indices]\n",
        "val_images = [images[i] for i in val_indices]\n",
        "test_images = [images[i] for i in test_indices]\n",
        "\n",
        "\n",
        "#preprocessing\n",
        "def preprocessing_images(X_tr):\n",
        "    X_tr = np.asarray(X_tr)\n",
        "    X_tr = X_tr.astype('float32')\n",
        "    X_tr /= 255\n",
        "    return X_tr\n",
        "\n",
        "train_images = preprocessing_images(train_images)\n",
        "val_images = preprocessing_images(val_images)\n",
        "test_images = preprocessing_images(test_images)\n",
        "\n",
        "\n",
        "\n",
        "# Use indices to select images for each dataset\n",
        "train_labels = [labels[i] for i in train_indices]\n",
        "val_labels = [labels[i] for i in val_indices]\n",
        "test_labels = [labels[i] for i in test_indices]\n",
        "\n",
        "\n",
        "def preprocessing_labels(labels):\n",
        "  labels = np.asarray(labels)\n",
        "  return labels\n",
        "\n",
        "train_labels = preprocessing_labels(train_labels)\n",
        "val_labels = preprocessing_labels(val_labels)\n",
        "test_labels = preprocessing_labels(test_labels)\n",
        "\n",
        "# Y_tr = np.asarray(Y_tr)\n",
        "batch_size = 64\n",
        "\n",
        "# Convert your training and validation data into TensorFlow datasets if not already\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"
      ],
      "metadata": {
        "id": "18OtaNIjREvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # HP\n",
        "\n",
        "# learning rate  = 1e-5\n",
        "# batch_size = 32\n",
        "# nb_epochs = 1"
      ],
      "metadata": {
        "id": "d7yIHqxkUzrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_and_evaluate(learning_rate, batch_size, nb_epochs):\n",
        "    # Define the model architecture with the base model frozen\n",
        "    vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "    vgg16_net.trainable = False  # Freeze the VGG16 model\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(vgg16_net)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Ensure this matches your classification needs\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epochs,\n",
        "              validation_data=(val_images, val_labels), shuffle=True, verbose=2)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    val_predictions = (model.predict(val_images).flatten() > 0.5).astype(int)\n",
        "    test_predictions = (model.predict(test_images).flatten() > 0.5).astype(int)\n",
        "\n",
        "    # Generate classification reports for validation and test sets\n",
        "    val_report = classification_report(val_labels, val_predictions, output_dict=True)\n",
        "    test_report = classification_report(test_labels, test_predictions, output_dict=True)\n",
        "\n",
        "    # Extract recall and F1-score for each class and averages\n",
        "    results = {\n",
        "        'val_recall_class_0': val_report['0']['recall'],\n",
        "        'val_f1_class_0': val_report['0']['f1-score'],\n",
        "        'val_recall_class_1': val_report['1']['recall'],\n",
        "        'val_f1_class_1': val_report['1']['f1-score'],\n",
        "        'val_recall_avg': val_report['macro avg']['recall'],\n",
        "        'val_f1_avg': val_report['macro avg']['f1-score'],\n",
        "        'test_recall_class_0': test_report['0']['recall'],\n",
        "        'test_f1_class_0': test_report['0']['f1-score'],\n",
        "        'test_recall_class_1': test_report['1']['recall'],\n",
        "        'test_f1_class_1': test_report['1']['f1-score'],\n",
        "        'test_recall_avg': test_report['macro avg']['recall'],\n",
        "        'test_f1_avg': test_report['macro avg']['f1-score']\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Define hyperparameters combinations\n",
        "learning_rates = [1e-06, 1e-05]\n",
        "batch_sizes = [32, 64]\n",
        "epochs = [1, 2, 3]\n",
        "\n",
        "# Loop over all combinations\n",
        "all_results = []\n",
        "for lr in learning_rates:\n",
        "    for batch in batch_sizes:\n",
        "        for epoch in epochs:\n",
        "            metrics = train_and_evaluate(lr, batch, epoch)\n",
        "            all_results.append((epoch, lr, batch) + tuple(metrics.values()))\n",
        "            print(f\"Epochs: {epoch}, Learning Rate: {lr}, Batch Size: {batch}, Metrics: {metrics}\")\n",
        "\n",
        "# Creating DataFrame\n",
        "df_columns = ['Epochs', 'Learning Rate', 'Batch Size', 'Val Recall Class 0', 'Val F1 Class 0', 'Val Recall Class 1', 'Val F1 Class 1', 'Val Recall Avg', 'Val F1 Avg', 'Test Recall Class 0', 'Test F1 Class 0', 'Test Recall Class 1', 'Test F1 Class 1', 'Test Recall Avg', 'Test F1 Avg']\n",
        "df_results = pd.DataFrame(all_results, columns=df_columns)\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9_t2udCJM4Q",
        "outputId": "ad299874-ae36-49e3-9f24-a87e48ce0745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 - 10s - loss: 0.1958 - accuracy: 0.9230 - val_loss: 0.1224 - val_accuracy: 0.9528 - 10s/epoch - 27ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-06, Batch Size: 32, Metrics: {'val_recall_class_0': 0.8990825688073395, 'val_f1_class_0': 0.9046153846153846, 'val_recall_class_1': 0.9705733130390665, 'val_f1_class_1': 0.9686075949367089, 'val_recall_avg': 0.934827940923203, 'val_f1_avg': 0.9366114897760467, 'test_recall_class_0': 0.9251908396946565, 'test_f1_class_0': 0.9273144605967867, 'test_recall_class_1': 0.9766497461928934, 'test_f1_class_1': 0.9759066700481867, 'test_recall_avg': 0.950920292943775, 'test_f1_avg': 0.9516105653224867}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "383/383 - 5s - loss: 0.1824 - accuracy: 0.9298 - val_loss: 0.1197 - val_accuracy: 0.9554 - 5s/epoch - 13ms/step\n",
            "Epoch 2/2\n",
            "383/383 - 3s - loss: 0.1156 - accuracy: 0.9547 - val_loss: 0.1064 - val_accuracy: 0.9573 - 3s/epoch - 9ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-06, Batch Size: 32, Metrics: {'val_recall_class_0': 0.9541284403669725, 'val_f1_class_0': 0.9176470588235294, 'val_recall_class_1': 0.9583967529173009, 'val_f1_class_1': 0.9712082262210797, 'val_recall_avg': 0.9562625966421368, 'val_f1_avg': 0.9444276425223046, 'test_recall_class_0': 0.9709923664122138, 'test_f1_class_0': 0.9318681318681318, 'test_recall_class_1': 0.9624365482233502, 'test_f1_class_1': 0.976061776061776, 'test_recall_avg': 0.9667144573177819, 'test_f1_avg': 0.953964953964954}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "383/383 - 5s - loss: 0.1782 - accuracy: 0.9304 - val_loss: 0.1197 - val_accuracy: 0.9539 - 5s/epoch - 13ms/step\n",
            "Epoch 2/3\n",
            "383/383 - 3s - loss: 0.1172 - accuracy: 0.9561 - val_loss: 0.1041 - val_accuracy: 0.9608 - 3s/epoch - 9ms/step\n",
            "Epoch 3/3\n",
            "383/383 - 4s - loss: 0.1044 - accuracy: 0.9599 - val_loss: 0.0935 - val_accuracy: 0.9638 - 4s/epoch - 10ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 13ms/step\n",
            "Epochs: 3, Learning Rate: 1e-06, Batch Size: 32, Metrics: {'val_recall_class_0': 0.926605504587156, 'val_f1_class_0': 0.9273144605967865, 'val_recall_class_1': 0.976154236428209, 'val_f1_class_1': 0.9759066700481867, 'val_recall_avg': 0.9513798705076825, 'val_f1_avg': 0.9516105653224866, 'test_recall_class_0': 0.934351145038168, 'test_f1_class_0': 0.9350649350649352, 'test_recall_class_1': 0.9786802030456853, 'test_f1_class_1': 0.978431870083735, 'test_recall_avg': 0.9565156740419266, 'test_f1_avg': 0.9567484025743351}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192/192 - 5s - loss: 0.2066 - accuracy: 0.9189 - val_loss: 0.1264 - val_accuracy: 0.9505 - 5s/epoch - 27ms/step\n",
            "83/83 [==============================] - 1s 11ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "Epochs: 1, Learning Rate: 1e-06, Batch Size: 64, Metrics: {'val_recall_class_0': 0.9113149847094801, 'val_f1_class_0': 0.9016641452344932, 'val_recall_class_1': 0.9634703196347032, 'val_f1_class_1': 0.9669042769857433, 'val_recall_avg': 0.9373926521720917, 'val_f1_avg': 0.9342842111101183, 'test_recall_class_0': 0.9374045801526718, 'test_f1_class_0': 0.9253956292388849, 'test_recall_class_1': 0.9705583756345177, 'test_f1_class_1': 0.974764211062962, 'test_recall_avg': 0.9539814778935948, 'test_f1_avg': 0.9500799201509234}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "192/192 - 4s - loss: 0.1960 - accuracy: 0.9236 - val_loss: 0.1245 - val_accuracy: 0.9493 - 4s/epoch - 21ms/step\n",
            "Epoch 2/2\n",
            "192/192 - 2s - loss: 0.1198 - accuracy: 0.9561 - val_loss: 0.1073 - val_accuracy: 0.9581 - 2s/epoch - 12ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-06, Batch Size: 64, Metrics: {'val_recall_class_0': 0.9464831804281345, 'val_f1_class_0': 0.9183976261127595, 'val_recall_class_1': 0.9619482496194824, 'val_f1_class_1': 0.9718093285494619, 'val_recall_avg': 0.9542157150238084, 'val_f1_avg': 0.9451034773311107, 'test_recall_class_0': 0.9541984732824428, 'test_f1_class_0': 0.9266123054114159, 'test_recall_class_1': 0.9649746192893401, 'test_f1_class_1': 0.9746218918226097, 'test_recall_avg': 0.9595865462858915, 'test_f1_avg': 0.9506170986170128}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "192/192 - 4s - loss: 0.2231 - accuracy: 0.9092 - val_loss: 0.1292 - val_accuracy: 0.9493 - 4s/epoch - 21ms/step\n",
            "Epoch 2/3\n",
            "192/192 - 3s - loss: 0.1249 - accuracy: 0.9547 - val_loss: 0.1108 - val_accuracy: 0.9554 - 3s/epoch - 13ms/step\n",
            "Epoch 3/3\n",
            "192/192 - 3s - loss: 0.1088 - accuracy: 0.9597 - val_loss: 0.1023 - val_accuracy: 0.9615 - 3s/epoch - 13ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-06, Batch Size: 64, Metrics: {'val_recall_class_0': 0.944954128440367, 'val_f1_class_0': 0.9244577412116678, 'val_recall_class_1': 0.9670218163368848, 'val_f1_class_1': 0.9741886020955789, 'val_recall_avg': 0.9559879723886259, 'val_f1_avg': 0.9493231716536233, 'test_recall_class_0': 0.9587786259541985, 'test_f1_class_0': 0.9338289962825278, 'test_recall_class_1': 0.9685279187817258, 'test_f1_class_1': 0.9772087067861716, 'test_recall_avg': 0.9636532723679622, 'test_f1_avg': 0.9555188515343497}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 - 7s - loss: 0.1809 - accuracy: 0.9274 - val_loss: 0.1178 - val_accuracy: 0.9535 - 7s/epoch - 19ms/step\n",
            "83/83 [==============================] - 2s 9ms/step\n",
            "83/83 [==============================] - 1s 9ms/step\n",
            "Epochs: 1, Learning Rate: 1e-05, Batch Size: 32, Metrics: {'val_recall_class_0': 0.9143730886850153, 'val_f1_class_0': 0.9074355083459787, 'val_recall_class_1': 0.9665144596651446, 'val_f1_class_1': 0.968972533062055, 'val_recall_avg': 0.94044377417508, 'val_f1_avg': 0.9382040207040169, 'test_recall_class_0': 0.932824427480916, 'test_f1_class_0': 0.9271623672230652, 'test_recall_class_1': 0.9736040609137055, 'test_f1_class_1': 0.9755849440488301, 'test_recall_avg': 0.9532142441973108, 'test_f1_avg': 0.9513736556359477}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "383/383 - 6s - loss: 0.1832 - accuracy: 0.9269 - val_loss: 0.1190 - val_accuracy: 0.9550 - 6s/epoch - 15ms/step\n",
            "Epoch 2/2\n",
            "383/383 - 4s - loss: 0.1157 - accuracy: 0.9566 - val_loss: 0.1034 - val_accuracy: 0.9615 - 4s/epoch - 10ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-05, Batch Size: 32, Metrics: {'val_recall_class_0': 0.9556574923547401, 'val_f1_class_0': 0.9252405625462621, 'val_recall_class_1': 0.9634703196347032, 'val_f1_class_1': 0.97409592203129, 'val_recall_avg': 0.9595639059947216, 'val_f1_avg': 0.9496682422887761, 'test_recall_class_0': 0.9648854961832061, 'test_f1_class_0': 0.9321533923303834, 'test_recall_class_1': 0.9649746192893401, 'test_f1_class_1': 0.9763739085772984, 'test_recall_avg': 0.9649300577362732, 'test_f1_avg': 0.9542636504538409}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "383/383 - 6s - loss: 0.1856 - accuracy: 0.9260 - val_loss: 0.1207 - val_accuracy: 0.9524 - 6s/epoch - 15ms/step\n",
            "Epoch 2/3\n",
            "383/383 - 4s - loss: 0.1137 - accuracy: 0.9580 - val_loss: 0.1057 - val_accuracy: 0.9585 - 4s/epoch - 10ms/step\n",
            "Epoch 3/3\n",
            "383/383 - 4s - loss: 0.1048 - accuracy: 0.9591 - val_loss: 0.0936 - val_accuracy: 0.9642 - 4s/epoch - 10ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-05, Batch Size: 32, Metrics: {'val_recall_class_0': 0.9342507645259939, 'val_f1_class_0': 0.9285714285714286, 'val_recall_class_1': 0.974124809741248, 'val_f1_class_1': 0.9761057447890187, 'val_recall_avg': 0.954187787133621, 'val_f1_avg': 0.9523385866802236, 'test_recall_class_0': 0.9465648854961832, 'test_f1_class_0': 0.9401061410159212, 'test_recall_class_1': 0.9776649746192894, 'test_f1_class_1': 0.9799033324853726, 'test_recall_avg': 0.9621149300577363, 'test_f1_avg': 0.9600047367506469}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192/192 - 4s - loss: 0.2276 - accuracy: 0.9066 - val_loss: 0.1313 - val_accuracy: 0.9493 - 4s/epoch - 20ms/step\n",
            "83/83 [==============================] - 1s 9ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-05, Batch Size: 64, Metrics: {'val_recall_class_0': 0.8929663608562691, 'val_f1_class_0': 0.8977709454265949, 'val_recall_class_1': 0.9680365296803652, 'val_f1_class_1': 0.9663205874905039, 'val_recall_avg': 0.9305014452683171, 'val_f1_avg': 0.9320457664585493, 'test_recall_class_0': 0.9251908396946565, 'test_f1_class_0': 0.9216730038022815, 'test_recall_class_1': 0.9725888324873097, 'test_f1_class_1': 0.9738246505717917, 'test_recall_avg': 0.9488898360909831, 'test_f1_avg': 0.9477488271870366}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "192/192 - 4s - loss: 0.2194 - accuracy: 0.9118 - val_loss: 0.1289 - val_accuracy: 0.9478 - 4s/epoch - 18ms/step\n",
            "Epoch 2/2\n",
            "192/192 - 2s - loss: 0.1220 - accuracy: 0.9540 - val_loss: 0.1085 - val_accuracy: 0.9570 - 2s/epoch - 12ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-05, Batch Size: 64, Metrics: {'val_recall_class_0': 0.9327217125382263, 'val_f1_class_0': 0.9152288072018003, 'val_recall_class_1': 0.9649923896499238, 'val_f1_class_1': 0.9711513913709471, 'val_recall_avg': 0.948857051094075, 'val_f1_avg': 0.9431900992863738, 'test_recall_class_0': 0.9511450381679389, 'test_f1_class_0': 0.9333333333333333, 'test_recall_class_1': 0.9710659898477157, 'test_f1_class_1': 0.9772669220945084, 'test_recall_avg': 0.9611055140078273, 'test_f1_avg': 0.9553001277139208}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "192/192 - 4s - loss: 0.1992 - accuracy: 0.9229 - val_loss: 0.1260 - val_accuracy: 0.9509 - 4s/epoch - 21ms/step\n",
            "Epoch 2/3\n",
            "192/192 - 3s - loss: 0.1219 - accuracy: 0.9544 - val_loss: 0.1067 - val_accuracy: 0.9585 - 3s/epoch - 13ms/step\n",
            "Epoch 3/3\n",
            "192/192 - 2s - loss: 0.1069 - accuracy: 0.9596 - val_loss: 0.1045 - val_accuracy: 0.9615 - 2s/epoch - 12ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-05, Batch Size: 64, Metrics: {'val_recall_class_0': 0.9617737003058104, 'val_f1_class_0': 0.9256806475349522, 'val_recall_class_1': 0.9614408929477423, 'val_f1_class_1': 0.9740426625546131, 'val_recall_avg': 0.9616072966267764, 'val_f1_avg': 0.9498616550447827, 'test_recall_class_0': 0.9740458015267176, 'test_f1_class_0': 0.935483870967742, 'test_recall_class_1': 0.9639593908629441, 'test_f1_class_1': 0.97735460627895, 'test_recall_avg': 0.9690025961948309, 'test_f1_avg': 0.956419238623346}\n",
            "    Epochs  Learning Rate  Batch Size  Val Recall Class 0  Val F1 Class 0  \\\n",
            "0        1       0.000001          32            0.899083        0.904615   \n",
            "1        2       0.000001          32            0.954128        0.917647   \n",
            "2        3       0.000001          32            0.926606        0.927314   \n",
            "3        1       0.000001          64            0.911315        0.901664   \n",
            "4        2       0.000001          64            0.946483        0.918398   \n",
            "5        3       0.000001          64            0.944954        0.924458   \n",
            "6        1       0.000010          32            0.914373        0.907436   \n",
            "7        2       0.000010          32            0.955657        0.925241   \n",
            "8        3       0.000010          32            0.934251        0.928571   \n",
            "9        1       0.000010          64            0.892966        0.897771   \n",
            "10       2       0.000010          64            0.932722        0.915229   \n",
            "11       3       0.000010          64            0.961774        0.925681   \n",
            "\n",
            "    Val Recall Class 1  Val F1 Class 1  Val Recall Avg  Val F1 Avg  \\\n",
            "0             0.970573        0.968608        0.934828    0.936611   \n",
            "1             0.958397        0.971208        0.956263    0.944428   \n",
            "2             0.976154        0.975907        0.951380    0.951611   \n",
            "3             0.963470        0.966904        0.937393    0.934284   \n",
            "4             0.961948        0.971809        0.954216    0.945103   \n",
            "5             0.967022        0.974189        0.955988    0.949323   \n",
            "6             0.966514        0.968973        0.940444    0.938204   \n",
            "7             0.963470        0.974096        0.959564    0.949668   \n",
            "8             0.974125        0.976106        0.954188    0.952339   \n",
            "9             0.968037        0.966321        0.930501    0.932046   \n",
            "10            0.964992        0.971151        0.948857    0.943190   \n",
            "11            0.961441        0.974043        0.961607    0.949862   \n",
            "\n",
            "    Test Recall Class 0  Test F1 Class 0  Test Recall Class 1  \\\n",
            "0              0.925191         0.927314             0.976650   \n",
            "1              0.970992         0.931868             0.962437   \n",
            "2              0.934351         0.935065             0.978680   \n",
            "3              0.937405         0.925396             0.970558   \n",
            "4              0.954198         0.926612             0.964975   \n",
            "5              0.958779         0.933829             0.968528   \n",
            "6              0.932824         0.927162             0.973604   \n",
            "7              0.964885         0.932153             0.964975   \n",
            "8              0.946565         0.940106             0.977665   \n",
            "9              0.925191         0.921673             0.972589   \n",
            "10             0.951145         0.933333             0.971066   \n",
            "11             0.974046         0.935484             0.963959   \n",
            "\n",
            "    Test F1 Class 1  Test Recall Avg  Test F1 Avg  \n",
            "0          0.975907         0.950920     0.951611  \n",
            "1          0.976062         0.966714     0.953965  \n",
            "2          0.978432         0.956516     0.956748  \n",
            "3          0.974764         0.953981     0.950080  \n",
            "4          0.974622         0.959587     0.950617  \n",
            "5          0.977209         0.963653     0.955519  \n",
            "6          0.975585         0.953214     0.951374  \n",
            "7          0.976374         0.964930     0.954264  \n",
            "8          0.979903         0.962115     0.960005  \n",
            "9          0.973825         0.948890     0.947749  \n",
            "10         0.977267         0.961106     0.955300  \n",
            "11         0.977355         0.969003     0.956419  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df_results' is the DataFrame from your code output\n",
        "# Select only columns related to the test set\n",
        "columns_of_interest = ['Epochs', 'Learning Rate', 'Batch Size', 'Test Recall Class 0', 'Test F1 Class 0', 'Test Recall Class 1', 'Test F1 Class 1', 'Test Recall Avg', 'Test F1 Avg']\n",
        "df_test_results = df_results[columns_of_interest]\n",
        "\n",
        "# Print the formatted DataFrame\n",
        "print(df_test_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbSwX4v6JwBY",
        "outputId": "480c3f27-6bff-4e89-aed3-c73ab439453b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Epochs  Learning Rate  Batch Size  Test Recall Class 0  Test F1 Class 0  \\\n",
            "0        1       0.000001          32             0.925191         0.927314   \n",
            "1        2       0.000001          32             0.970992         0.931868   \n",
            "2        3       0.000001          32             0.934351         0.935065   \n",
            "3        1       0.000001          64             0.937405         0.925396   \n",
            "4        2       0.000001          64             0.954198         0.926612   \n",
            "5        3       0.000001          64             0.958779         0.933829   \n",
            "6        1       0.000010          32             0.932824         0.927162   \n",
            "7        2       0.000010          32             0.964885         0.932153   \n",
            "8        3       0.000010          32             0.946565         0.940106   \n",
            "9        1       0.000010          64             0.925191         0.921673   \n",
            "10       2       0.000010          64             0.951145         0.933333   \n",
            "11       3       0.000010          64             0.974046         0.935484   \n",
            "\n",
            "    Test Recall Class 1  Test F1 Class 1  Test Recall Avg  Test F1 Avg  \n",
            "0              0.976650         0.975907         0.950920     0.951611  \n",
            "1              0.962437         0.976062         0.966714     0.953965  \n",
            "2              0.978680         0.978432         0.956516     0.956748  \n",
            "3              0.970558         0.974764         0.953981     0.950080  \n",
            "4              0.964975         0.974622         0.959587     0.950617  \n",
            "5              0.968528         0.977209         0.963653     0.955519  \n",
            "6              0.973604         0.975585         0.953214     0.951374  \n",
            "7              0.964975         0.976374         0.964930     0.954264  \n",
            "8              0.977665         0.979903         0.962115     0.960005  \n",
            "9              0.972589         0.973825         0.948890     0.947749  \n",
            "10             0.971066         0.977267         0.961106     0.955300  \n",
            "11             0.963959         0.977355         0.969003     0.956419  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_and_evaluate(learning_rate, batch_size, nb_epochs):\n",
        "    # Define the model architecture\n",
        "    vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "    vgg16_net.trainable = True\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(vgg16_net)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Ensure this matches your classification needs\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epochs,\n",
        "              validation_data=(val_images, val_labels), shuffle=True, verbose=2)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    val_predictions = (model.predict(val_images).flatten() > 0.5).astype(int)\n",
        "\n",
        "    # Predict on the test set\n",
        "    test_predictions = (model.predict(test_images).flatten() > 0.5).astype(int)\n",
        "\n",
        "    # Generate classification reports for validation and test sets\n",
        "    val_report = classification_report(val_labels, val_predictions, output_dict=True)\n",
        "    test_report = classification_report(test_labels, test_predictions, output_dict=True)\n",
        "\n",
        "    # Extract recall and F1-score for each class and averages\n",
        "    results = {\n",
        "        'val_recall_class_0': val_report['0']['recall'],\n",
        "        'val_f1_class_0': val_report['0']['f1-score'],\n",
        "        'val_recall_class_1': val_report['1']['recall'],\n",
        "        'val_f1_class_1': val_report['1']['f1-score'],\n",
        "        'val_recall_avg': val_report['macro avg']['recall'],\n",
        "        'val_f1_avg': val_report['macro avg']['f1-score'],\n",
        "        'test_recall_class_0': test_report['0']['recall'],\n",
        "        'test_f1_class_0': test_report['0']['f1-score'],\n",
        "        'test_recall_class_1': test_report['1']['recall'],\n",
        "        'test_f1_class_1': test_report['1']['f1-score'],\n",
        "        'test_recall_avg': test_report['macro avg']['recall'],\n",
        "        'test_f1_avg': test_report['macro avg']['f1-score']\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Define hyperparameters combinations\n",
        "learning_rates = [1e-06, 1e-05]\n",
        "batch_sizes = [32, 64]\n",
        "epochs = [1, 2, 3]\n",
        "\n",
        "# Loop over all combinations\n",
        "all_results = []\n",
        "for lr in learning_rates:\n",
        "    for batch in batch_sizes:\n",
        "        for epoch in epochs:\n",
        "            metrics = train_and_evaluate(lr, batch, epoch)\n",
        "            all_results.append((epoch, lr, batch) + tuple(metrics.values()))\n",
        "            print(f\"Epochs: {epoch}, Learning Rate: {lr}, Batch Size: {batch}, Metrics: {metrics}\")\n",
        "\n",
        "# Creating DataFrame\n",
        "df_columns = ['Epochs', 'Learning Rate', 'Batch Size', 'Val Recall Class 0', 'Val F1 Class 0', 'Val Recall Class 1', 'Val F1 Class 1', 'Val Recall Avg', 'Val F1 Avg', 'Test Recall Class 0', 'Test F1 Class 0', 'Test Recall Class 1', 'Test F1 Class 1', 'Test Recall Avg', 'Test F1 Avg']\n",
        "df_results = pd.DataFrame(all_results, columns=df_columns)\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cH4WwXW2xfL",
        "outputId": "c5a0c6b0-e425-40ef-96fa-79e68de9499e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 - 24s - loss: 0.4336 - accuracy: 0.8418 - val_loss: 0.2937 - val_accuracy: 0.8667 - 24s/epoch - 62ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-06, Batch Size: 32, Metrics: {'val_recall_class_0': 0.5198776758409785, 'val_f1_class_0': 0.6601941747572816, 'val_recall_class_1': 0.9817351598173516, 'val_f1_class_1': 0.9170616113744076, 'val_recall_avg': 0.7508064178291651, 'val_f1_avg': 0.7886278930658446, 'test_recall_class_0': 0.5251908396946565, 'test_f1_class_0': 0.6596356663470758, 'test_recall_class_1': 0.9776649746192894, 'test_f1_class_1': 0.9156168290943666, 'test_recall_avg': 0.7514279071569729, 'test_f1_avg': 0.7876262477207212}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "383/383 - 16s - loss: 0.1962 - accuracy: 0.9233 - val_loss: 0.0789 - val_accuracy: 0.9714 - 16s/epoch - 42ms/step\n",
            "Epoch 2/2\n",
            "383/383 - 11s - loss: 0.2463 - accuracy: 0.9251 - val_loss: 0.5173 - val_accuracy: 0.7509 - 11s/epoch - 29ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-06, Batch Size: 32, Metrics: {'val_recall_class_0': 0.0, 'val_f1_class_0': 0.0, 'val_recall_class_1': 1.0, 'val_f1_class_1': 0.8577023498694517, 'val_recall_avg': 0.5, 'val_f1_avg': 0.42885117493472585, 'test_recall_class_0': 0.0, 'test_f1_class_0': 0.0, 'test_recall_class_1': 1.0, 'test_f1_class_1': 0.8574537540805224, 'test_recall_avg': 0.5, 'test_f1_avg': 0.4287268770402612}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "383/383 - 15s - loss: 0.1866 - accuracy: 0.9289 - val_loss: 0.0676 - val_accuracy: 0.9768 - 15s/epoch - 40ms/step\n",
            "Epoch 2/3\n",
            "383/383 - 11s - loss: 0.0664 - accuracy: 0.9789 - val_loss: 0.0328 - val_accuracy: 0.9882 - 11s/epoch - 29ms/step\n",
            "Epoch 3/3\n",
            "383/383 - 11s - loss: 0.1002 - accuracy: 0.9705 - val_loss: 0.0361 - val_accuracy: 0.9901 - 11s/epoch - 29ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-06, Batch Size: 32, Metrics: {'val_recall_class_0': 0.9770642201834863, 'val_f1_class_0': 0.9800613496932515, 'val_recall_class_1': 0.9944190766108574, 'val_f1_class_1': 0.99341104916371, 'val_recall_avg': 0.9857416483971718, 'val_f1_avg': 0.9867361994284808, 'test_recall_class_0': 0.966412213740458, 'test_f1_class_0': 0.9745958429561202, 'test_recall_class_1': 0.9944162436548223, 'test_f1_class_1': 0.9916476841305998, 'test_recall_avg': 0.9804142286976402, 'test_f1_avg': 0.98312176354336}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192/192 - 15s - loss: 0.3856 - accuracy: 0.8682 - val_loss: 0.0761 - val_accuracy: 0.9760 - 15s/epoch - 77ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-06, Batch Size: 64, Metrics: {'val_recall_class_0': 0.9159021406727829, 'val_f1_class_0': 0.9500396510705789, 'val_recall_class_1': 0.9959411466260781, 'val_f1_class_1': 0.984206568062171, 'val_recall_avg': 0.9559216436494304, 'val_f1_avg': 0.9671231095663749, 'test_recall_class_0': 0.9267175572519084, 'test_f1_class_0': 0.9559055118110236, 'test_recall_class_1': 0.9959390862944163, 'test_f1_class_1': 0.9859296482412061, 'test_recall_avg': 0.9613283217731623, 'test_f1_avg': 0.9709175800261148}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "192/192 - 11s - loss: 0.3551 - accuracy: 0.8550 - val_loss: 0.0685 - val_accuracy: 0.9745 - 11s/epoch - 60ms/step\n",
            "Epoch 2/2\n",
            "192/192 - 7s - loss: 0.1008 - accuracy: 0.9686 - val_loss: 0.1376 - val_accuracy: 0.9573 - 7s/epoch - 37ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-06, Batch Size: 64, Metrics: {'val_recall_class_0': 0.8348623853211009, 'val_f1_class_0': 0.9069767441860465, 'val_recall_class_1': 0.9979705733130391, 'val_f1_class_1': 0.972318339100346, 'val_recall_avg': 0.9164164793170699, 'val_f1_avg': 0.9396475416431962, 'test_recall_class_0': 0.8519083969465648, 'test_f1_class_0': 0.9185185185185185, 'test_recall_class_1': 0.9989847715736041, 'test_f1_class_1': 0.97546468401487, 'test_recall_avg': 0.9254465842600845, 'test_f1_avg': 0.9469916012666942}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "192/192 - 12s - loss: 0.3449 - accuracy: 0.8531 - val_loss: 0.1235 - val_accuracy: 0.9615 - 12s/epoch - 63ms/step\n",
            "Epoch 2/3\n",
            "192/192 - 7s - loss: 0.0753 - accuracy: 0.9758 - val_loss: 0.0649 - val_accuracy: 0.9771 - 7s/epoch - 39ms/step\n",
            "Epoch 3/3\n",
            "192/192 - 7s - loss: 0.1066 - accuracy: 0.9673 - val_loss: 0.0526 - val_accuracy: 0.9821 - 7s/epoch - 37ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-06, Batch Size: 64, Metrics: {'val_recall_class_0': 0.9892966360856269, 'val_f1_class_0': 0.964951528709918, 'val_recall_class_1': 0.9797057331303907, 'val_f1_class_1': 0.9879764645689434, 'val_recall_avg': 0.9845011846080087, 'val_f1_avg': 0.9764639966394306, 'test_recall_class_0': 0.9923664122137404, 'test_f1_class_0': 0.9643916913946587, 'test_recall_class_1': 0.9781725888324873, 'test_f1_class_1': 0.9876986160943105, 'test_recall_avg': 0.9852695005231138, 'test_f1_avg': 0.9760451537444846}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 - 15s - loss: 0.2316 - accuracy: 0.9113 - val_loss: 0.0606 - val_accuracy: 0.9794 - 15s/epoch - 40ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 9ms/step\n",
            "Epochs: 1, Learning Rate: 1e-05, Batch Size: 32, Metrics: {'val_recall_class_0': 0.9724770642201835, 'val_f1_class_0': 0.9592760180995474, 'val_recall_class_1': 0.9817351598173516, 'val_f1_class_1': 0.9862385321100918, 'val_recall_avg': 0.9771061120187676, 'val_f1_avg': 0.9727572751048197, 'test_recall_class_0': 0.9755725190839695, 'test_f1_class_0': 0.969650986342944, 'test_recall_class_1': 0.9878172588832488, 'test_f1_class_1': 0.9898270600203459, 'test_recall_avg': 0.9816948889836091, 'test_f1_avg': 0.979739023181645}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "383/383 - 22s - loss: 0.2687 - accuracy: 0.9056 - val_loss: 0.1097 - val_accuracy: 0.9585 - 22s/epoch - 56ms/step\n",
            "Epoch 2/2\n",
            "383/383 - 11s - loss: 0.0632 - accuracy: 0.9784 - val_loss: 0.0510 - val_accuracy: 0.9897 - 11s/epoch - 30ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-05, Batch Size: 32, Metrics: {'val_recall_class_0': 0.9709480122324159, 'val_f1_class_0': 0.9791827293754819, 'val_recall_class_1': 0.9959411466260781, 'val_f1_class_1': 0.9931697444978498, 'val_recall_avg': 0.983444579429247, 'val_f1_avg': 0.9861762369366658, 'test_recall_class_0': 0.9725190839694656, 'test_f1_class_0': 0.9777436684574061, 'test_recall_class_1': 0.9944162436548223, 'test_f1_class_1': 0.9926526475804408, 'test_recall_avg': 0.983467663812144, 'test_f1_avg': 0.9851981580189235}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "383/383 - 15s - loss: 0.2734 - accuracy: 0.8889 - val_loss: 0.0905 - val_accuracy: 0.9611 - 15s/epoch - 40ms/step\n",
            "Epoch 2/3\n",
            "383/383 - 11s - loss: 0.1245 - accuracy: 0.9567 - val_loss: 0.0840 - val_accuracy: 0.9695 - 11s/epoch - 30ms/step\n",
            "Epoch 3/3\n",
            "383/383 - 11s - loss: 0.1486 - accuracy: 0.9575 - val_loss: 0.1521 - val_accuracy: 0.9383 - 11s/epoch - 30ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-05, Batch Size: 32, Metrics: {'val_recall_class_0': 0.7951070336391437, 'val_f1_class_0': 0.86522462562396, 'val_recall_class_1': 0.9857940131912735, 'val_f1_class_1': 0.9599802371541502, 'val_recall_avg': 0.8904505234152086, 'val_f1_avg': 0.9126024313890551, 'test_recall_class_0': 0.7786259541984732, 'test_f1_class_0': 0.8578637510513035, 'test_recall_class_1': 0.9878172588832488, 'test_f1_class_1': 0.9583846343265207, 'test_recall_avg': 0.883221606540861, 'test_f1_avg': 0.9081241926889121}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192/192 - 12s - loss: 0.2627 - accuracy: 0.8927 - val_loss: 0.0938 - val_accuracy: 0.9627 - 12s/epoch - 63ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-05, Batch Size: 64, Metrics: {'val_recall_class_0': 0.8685015290519877, 'val_f1_class_0': 0.9205834683954619, 'val_recall_class_1': 0.9939117199391172, 'val_f1_class_1': 0.975597609561753, 'val_recall_avg': 0.9312066244955525, 'val_f1_avg': 0.9480905389786074, 'test_recall_class_0': 0.8656488549618321, 'test_f1_class_0': 0.9242053789731051, 'test_recall_class_1': 0.9974619289340102, 'test_f1_class_1': 0.976882923191648, 'test_recall_avg': 0.9315553919479211, 'test_f1_avg': 0.9505441510823766}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "192/192 - 11s - loss: 0.2780 - accuracy: 0.8962 - val_loss: 0.0846 - val_accuracy: 0.9775 - 11s/epoch - 60ms/step\n",
            "Epoch 2/2\n",
            "192/192 - 7s - loss: 0.0617 - accuracy: 0.9793 - val_loss: 0.0354 - val_accuracy: 0.9897 - 7s/epoch - 37ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-05, Batch Size: 64, Metrics: {'val_recall_class_0': 0.9801223241590215, 'val_f1_class_0': 0.9793735676088617, 'val_recall_class_1': 0.9928970065956367, 'val_f1_class_1': 0.9931489469677747, 'val_recall_avg': 0.9865096653773291, 'val_f1_avg': 0.9862612572883183, 'test_recall_class_0': 0.981679389312977, 'test_f1_class_0': 0.9854406130268198, 'test_recall_class_1': 0.9964467005076142, 'test_f1_class_1': 0.9951837769328263, 'test_recall_avg': 0.9890630449102956, 'test_f1_avg': 0.990312194979823}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "192/192 - 12s - loss: 0.2816 - accuracy: 0.8897 - val_loss: 0.0591 - val_accuracy: 0.9802 - 12s/epoch - 61ms/step\n",
            "Epoch 2/3\n",
            "192/192 - 7s - loss: 0.0643 - accuracy: 0.9789 - val_loss: 0.0478 - val_accuracy: 0.9817 - 7s/epoch - 39ms/step\n",
            "Epoch 3/3\n",
            "192/192 - 7s - loss: 0.0481 - accuracy: 0.9837 - val_loss: 0.0461 - val_accuracy: 0.9848 - 7s/epoch - 39ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-05, Batch Size: 64, Metrics: {'val_recall_class_0': 0.9480122324159022, 'val_f1_class_0': 0.96875, 'val_recall_class_1': 0.9969558599695586, 'val_f1_class_1': 0.9899244332493703, 'val_recall_avg': 0.9724840461927304, 'val_f1_avg': 0.9793372166246852, 'test_recall_class_0': 0.9419847328244275, 'test_f1_class_0': 0.966327329678935, 'test_recall_class_1': 0.9974619289340102, 'test_f1_class_1': 0.9891769443745282, 'test_recall_avg': 0.9697233308792188, 'test_f1_avg': 0.9777521370267316}\n",
            "    Epochs  Learning Rate  Batch Size  Val Recall Class 0  Val F1 Class 0  \\\n",
            "0        1       0.000001          32            0.519878        0.660194   \n",
            "1        2       0.000001          32            0.000000        0.000000   \n",
            "2        3       0.000001          32            0.977064        0.980061   \n",
            "3        1       0.000001          64            0.915902        0.950040   \n",
            "4        2       0.000001          64            0.834862        0.906977   \n",
            "5        3       0.000001          64            0.989297        0.964952   \n",
            "6        1       0.000010          32            0.972477        0.959276   \n",
            "7        2       0.000010          32            0.970948        0.979183   \n",
            "8        3       0.000010          32            0.795107        0.865225   \n",
            "9        1       0.000010          64            0.868502        0.920583   \n",
            "10       2       0.000010          64            0.980122        0.979374   \n",
            "11       3       0.000010          64            0.948012        0.968750   \n",
            "\n",
            "    Val Recall Class 1  Val F1 Class 1  Val Recall Avg  Val F1 Avg  \\\n",
            "0             0.981735        0.917062        0.750806    0.788628   \n",
            "1             1.000000        0.857702        0.500000    0.428851   \n",
            "2             0.994419        0.993411        0.985742    0.986736   \n",
            "3             0.995941        0.984207        0.955922    0.967123   \n",
            "4             0.997971        0.972318        0.916416    0.939648   \n",
            "5             0.979706        0.987976        0.984501    0.976464   \n",
            "6             0.981735        0.986239        0.977106    0.972757   \n",
            "7             0.995941        0.993170        0.983445    0.986176   \n",
            "8             0.985794        0.959980        0.890451    0.912602   \n",
            "9             0.993912        0.975598        0.931207    0.948091   \n",
            "10            0.992897        0.993149        0.986510    0.986261   \n",
            "11            0.996956        0.989924        0.972484    0.979337   \n",
            "\n",
            "    Test Recall Class 0  Test F1 Class 0  Test Recall Class 1  \\\n",
            "0              0.525191         0.659636             0.977665   \n",
            "1              0.000000         0.000000             1.000000   \n",
            "2              0.966412         0.974596             0.994416   \n",
            "3              0.926718         0.955906             0.995939   \n",
            "4              0.851908         0.918519             0.998985   \n",
            "5              0.992366         0.964392             0.978173   \n",
            "6              0.975573         0.969651             0.987817   \n",
            "7              0.972519         0.977744             0.994416   \n",
            "8              0.778626         0.857864             0.987817   \n",
            "9              0.865649         0.924205             0.997462   \n",
            "10             0.981679         0.985441             0.996447   \n",
            "11             0.941985         0.966327             0.997462   \n",
            "\n",
            "    Test F1 Class 1  Test Recall Avg  Test F1 Avg  \n",
            "0          0.915617         0.751428     0.787626  \n",
            "1          0.857454         0.500000     0.428727  \n",
            "2          0.991648         0.980414     0.983122  \n",
            "3          0.985930         0.961328     0.970918  \n",
            "4          0.975465         0.925447     0.946992  \n",
            "5          0.987699         0.985270     0.976045  \n",
            "6          0.989827         0.981695     0.979739  \n",
            "7          0.992653         0.983468     0.985198  \n",
            "8          0.958385         0.883222     0.908124  \n",
            "9          0.976883         0.931555     0.950544  \n",
            "10         0.995184         0.989063     0.990312  \n",
            "11         0.989177         0.969723     0.977752  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df_results' is the DataFrame from your code output\n",
        "# Select only columns related to the test set\n",
        "columns_of_interest = ['Epochs', 'Learning Rate', 'Batch Size', 'Test Recall Class 0', 'Test F1 Class 0', 'Test Recall Class 1', 'Test F1 Class 1', 'Test Recall Avg', 'Test F1 Avg']\n",
        "df_test_results = df_results[columns_of_interest]\n",
        "\n",
        "# Print the formatted DataFrame\n",
        "print(df_test_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LGbDLn560U9",
        "outputId": "4e39bf6f-663f-48ef-a596-0f9bca15bbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Epochs  Learning Rate  Batch Size  Test Recall Class 0  Test F1 Class 0  \\\n",
            "0        1       0.000001          32             0.525191         0.659636   \n",
            "1        2       0.000001          32             0.000000         0.000000   \n",
            "2        3       0.000001          32             0.966412         0.974596   \n",
            "3        1       0.000001          64             0.926718         0.955906   \n",
            "4        2       0.000001          64             0.851908         0.918519   \n",
            "5        3       0.000001          64             0.992366         0.964392   \n",
            "6        1       0.000010          32             0.975573         0.969651   \n",
            "7        2       0.000010          32             0.972519         0.977744   \n",
            "8        3       0.000010          32             0.778626         0.857864   \n",
            "9        1       0.000010          64             0.865649         0.924205   \n",
            "10       2       0.000010          64             0.981679         0.985441   \n",
            "11       3       0.000010          64             0.941985         0.966327   \n",
            "\n",
            "    Test Recall Class 1  Test F1 Class 1  Test Recall Avg  Test F1 Avg  \n",
            "0              0.977665         0.915617         0.751428     0.787626  \n",
            "1              1.000000         0.857454         0.500000     0.428727  \n",
            "2              0.994416         0.991648         0.980414     0.983122  \n",
            "3              0.995939         0.985930         0.961328     0.970918  \n",
            "4              0.998985         0.975465         0.925447     0.946992  \n",
            "5              0.978173         0.987699         0.985270     0.976045  \n",
            "6              0.987817         0.989827         0.981695     0.979739  \n",
            "7              0.994416         0.992653         0.983468     0.985198  \n",
            "8              0.987817         0.958385         0.883222     0.908124  \n",
            "9              0.997462         0.976883         0.931555     0.950544  \n",
            "10             0.996447         0.995184         0.989063     0.990312  \n",
            "11             0.997462         0.989177         0.969723     0.977752  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data creation (replace this with your actual DataFrame loading method)\n",
        "data = {\n",
        "    'Epochs': [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
        "    'Learning Rate': [1e-6]*6 + [1e-5]*6,\n",
        "    'Batch Size': [32]*3 + [64]*3 + [32]*3 + [64]*3,\n",
        "    'Test Recall Class 0': [0.525, 0.000, 0.966, 0.927, 0.852, 0.992, 0.976, 0.973, 0.779, 0.866, 0.982, 0.942],\n",
        "    'Test F1 Class 0': [0.660, 0.000, 0.975, 0.956, 0.919, 0.964, 0.970, 0.978, 0.858, 0.924, 0.985, 0.966],\n",
        "    'Test Recall Class 1': [0.978, 1.000, 0.994, 0.996, 0.999, 0.978, 0.988, 0.994, 0.988, 0.997, 0.996, 0.997],\n",
        "    'Test F1 Class 1': [0.916, 0.857, 0.992, 0.986, 0.975, 0.988, 0.990, 0.993, 0.958, 0.977, 0.995, 0.989],\n",
        "    'Test Recall Avg': [0.751, 0.500, 0.980, 0.961, 0.925, 0.985, 0.982, 0.983, 0.883, 0.932, 0.989, 0.970],\n",
        "    'Test F1 Avg': [0.788, 0.429, 0.983, 0.971, 0.947, 0.976, 0.980, 0.985, 0.908, 0.951, 0.990, 0.978]\n",
        "}\n",
        "df_results = pd.DataFrame(data)\n",
        "\n",
        "# Formatting similar to classification_report\n",
        "grouped_results = df_results.groupby('Epochs').agg({\n",
        "    'Test Recall Class 0': 'mean',\n",
        "    'Test F1 Class 0': 'mean',\n",
        "    'Test Recall Class 1': 'mean',\n",
        "    'Test F1 Class 1': 'mean',\n",
        "    'Test Recall Avg': 'mean',\n",
        "    'Test F1 Avg': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Custom print format\n",
        "print(\"Classification Report:\\n\")\n",
        "print(\"{:<11} {:<15} {:<15} {:<15} {:<15}\".format(\"\", \"Precision\", \"Recall\", \"F1-score\", \"Support\"))\n",
        "for index, row in grouped_results.iterrows():\n",
        "    print(f\"Epoch {row['Epochs']}:\")\n",
        "    print(\"{:<11} {:<15} {:<15} {:<15} {:<15}\".format(\"Class 0\", round(row['Test F1 Class 0'], 2), round(row['Test Recall Class 0'], 2), round(row['Test F1 Class 0'], 2), \"\"))\n",
        "    print(\"{:<11} {:<15} {:<15} {:<15} {:<15}\".format(\"Class 1\", round(row['Test F1 Class 1'], 2), round(row['Test Recall Class 1'], 2), round(row['Test F1 Class 1'], 2), \"\"))\n",
        "    print(\"{:<11} {:<15} {:<15} {:<15} {:<15}\".format(\"Avg/Total\", round(row['Test F1 Avg'], 2), round(row['Test Recall Avg'], 2), round(row['Test F1 Avg'], 2), \"\"))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTFqKSTy7vl3",
        "outputId": "2df59342-0a54-46a4-f111-a2920a563108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "            Precision       Recall          F1-score        Support        \n",
            "Epoch 1.0:\n",
            "Class 0     0.88            0.82            0.88                           \n",
            "Class 1     0.97            0.99            0.97                           \n",
            "Avg/Total   0.92            0.91            0.92                           \n",
            "\n",
            "\n",
            "Epoch 2.0:\n",
            "Class 0     0.72            0.7             0.72                           \n",
            "Class 1     0.96            1.0             0.96                           \n",
            "Avg/Total   0.84            0.85            0.84                           \n",
            "\n",
            "\n",
            "Epoch 3.0:\n",
            "Class 0     0.94            0.92            0.94                           \n",
            "Class 1     0.98            0.99            0.98                           \n",
            "Avg/Total   0.96            0.95            0.96                           \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Flatten, Dense, Activation, Dropout\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# import pandas as pd\n",
        "# from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# def train_and_evaluate(learning_rate, batch_size, nb_epochs):\n",
        "#     # Define the model architecture\n",
        "#     vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "#     vgg16_net.trainable = True\n",
        "\n",
        "#     model = Sequential()\n",
        "#     model.add(vgg16_net)\n",
        "#     model.add(Flatten())\n",
        "#     model.add(Dense(256, activation='relu'))\n",
        "#     model.add(Dropout(0.5))\n",
        "#     model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#     # Compile the model\n",
        "#     model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "\n",
        "#     # Train the model\n",
        "#     model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epochs,\n",
        "#               validation_data=(val_images, val_labels), shuffle=True, verbose=2)\n",
        "\n",
        "#     # Predict on the validation set\n",
        "#     val_predictions = model.predict(val_images).flatten()\n",
        "#     val_binary_predictions = val_predictions > 0.5\n",
        "\n",
        "#     # Predict on the test set\n",
        "#     test_predictions = model.predict(test_images).flatten()\n",
        "#     test_binary_predictions = test_predictions > 0.5\n",
        "\n",
        "#     # Calculate MCC for validation and test sets\n",
        "#     val_mcc = matthews_corrcoef(val_labels, val_binary_predictions)\n",
        "#     test_mcc = matthews_corrcoef(test_labels, test_binary_predictions)\n",
        "\n",
        "#     return val_mcc, test_mcc\n",
        "\n",
        "# # Define hyperparameters combinations\n",
        "# learning_rates = [1e-06, 1e-05]\n",
        "# batch_sizes = [32, 64]\n",
        "# epochs = [1, 2, 3]\n",
        "\n",
        "# # Loop over all combinations\n",
        "# results = []\n",
        "# for lr in learning_rates:\n",
        "#     for batch in batch_sizes:\n",
        "#         for epoch in epochs:\n",
        "#             val_mcc, test_mcc = train_and_evaluate(lr, batch, epoch)\n",
        "#             results.append((epoch, lr, batch, val_mcc, test_mcc))\n",
        "#             print(f\"Epochs: {epoch}, Learning Rate: {lr}, Batch Size: {batch}, Validation MCC: {val_mcc}, Test MCC: {test_mcc}\")\n",
        "#             df_results = pd.DataFrame(results, columns=['Epochs', 'Learning Rate', 'Batch Size', 'Validation MCC', 'Test MCC'])\n",
        "#             print(df_results)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5oqp0zAU7Mr",
        "outputId": "fecd16fe-5f33-4850-cdc3-fb70c1379ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 - 31s - loss: 0.5807 - accuracy: 0.7463 - val_loss: 0.5736 - val_accuracy: 0.7509 - 31s/epoch - 40ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-06, Batch Size: 16, Validation MCC: 0.0, Test MCC: 0.0\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16             0.0       0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "766/766 - 22s - loss: 0.2620 - accuracy: 0.8957 - val_loss: 0.0624 - val_accuracy: 0.9741 - 22s/epoch - 29ms/step\n",
            "Epoch 2/2\n",
            "766/766 - 18s - loss: 0.1717 - accuracy: 0.9405 - val_loss: 0.1357 - val_accuracy: 0.9573 - 18s/epoch - 24ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-06, Batch Size: 16, Validation MCC: 0.892703378082925, Test MCC: 0.8920491510147911\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "766/766 - 22s - loss: 0.2683 - accuracy: 0.9029 - val_loss: 0.1517 - val_accuracy: 0.9467 - 22s/epoch - 29ms/step\n",
            "Epoch 2/3\n",
            "766/766 - 19s - loss: 0.5317 - accuracy: 0.7944 - val_loss: 0.4979 - val_accuracy: 0.7509 - 19s/epoch - 24ms/step\n",
            "Epoch 3/3\n",
            "766/766 - 18s - loss: 0.2073 - accuracy: 0.9178 - val_loss: 0.1609 - val_accuracy: 0.9406 - 18s/epoch - 23ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-06, Batch Size: 16, Validation MCC: 0.838530862262231, Test MCC: 0.8412731596929467\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n",
            "2       3       0.000001          16        0.838531  0.841273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 - 18s - loss: 0.2947 - accuracy: 0.8878 - val_loss: 0.0816 - val_accuracy: 0.9672 - 18s/epoch - 48ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-06, Batch Size: 32, Validation MCC: 0.9149169330205958, Test MCC: 0.9420967038834908\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n",
            "2       3       0.000001          16        0.838531  0.841273\n",
            "3       1       0.000001          32        0.914917  0.942097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "383/383 - 15s - loss: 0.2413 - accuracy: 0.9106 - val_loss: 0.0653 - val_accuracy: 0.9794 - 15s/epoch - 40ms/step\n",
            "Epoch 2/2\n",
            "383/383 - 11s - loss: 0.0669 - accuracy: 0.9781 - val_loss: 0.2691 - val_accuracy: 0.8853 - 11s/epoch - 29ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-06, Batch Size: 32, Validation MCC: 0.7611555850224282, Test MCC: 0.7969423513898389\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n",
            "2       3       0.000001          16        0.838531  0.841273\n",
            "3       1       0.000001          32        0.914917  0.942097\n",
            "4       2       0.000001          32        0.761156  0.796942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "383/383 - 15s - loss: 0.2758 - accuracy: 0.8961 - val_loss: 0.2136 - val_accuracy: 0.9230 - 15s/epoch - 40ms/step\n",
            "Epoch 2/3\n",
            "383/383 - 11s - loss: 0.1370 - accuracy: 0.9562 - val_loss: 0.0646 - val_accuracy: 0.9813 - 11s/epoch - 29ms/step\n",
            "Epoch 3/3\n",
            "383/383 - 11s - loss: 0.0542 - accuracy: 0.9829 - val_loss: 0.0579 - val_accuracy: 0.9844 - 11s/epoch - 29ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-06, Batch Size: 32, Validation MCC: 0.9581245967361154, Test MCC: 0.9642597467183335\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n",
            "2       3       0.000001          16        0.838531  0.841273\n",
            "3       1       0.000001          32        0.914917  0.942097\n",
            "4       2       0.000001          32        0.761156  0.796942\n",
            "5       3       0.000001          32        0.958125  0.964260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192/192 - 13s - loss: 0.2885 - accuracy: 0.8922 - val_loss: 0.0666 - val_accuracy: 0.9775 - 13s/epoch - 70ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-06, Batch Size: 64, Validation MCC: 0.9404908110994091, Test MCC: 0.9457279072751856\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n",
            "2       3       0.000001          16        0.838531  0.841273\n",
            "3       1       0.000001          32        0.914917  0.942097\n",
            "4       2       0.000001          32        0.761156  0.796942\n",
            "5       3       0.000001          32        0.958125  0.964260\n",
            "6       1       0.000001          64        0.940491  0.945728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "192/192 - 11s - loss: 0.3503 - accuracy: 0.8798 - val_loss: 0.0578 - val_accuracy: 0.9825 - 11s/epoch - 59ms/step\n",
            "Epoch 2/2\n",
            "192/192 - 7s - loss: 0.1391 - accuracy: 0.9562 - val_loss: 0.1211 - val_accuracy: 0.9512 - 7s/epoch - 37ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-06, Batch Size: 64, Validation MCC: 0.8830695564175272, Test MCC: 0.8938473140992148\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n",
            "2       3       0.000001          16        0.838531  0.841273\n",
            "3       1       0.000001          32        0.914917  0.942097\n",
            "4       2       0.000001          32        0.761156  0.796942\n",
            "5       3       0.000001          32        0.958125  0.964260\n",
            "6       1       0.000001          64        0.940491  0.945728\n",
            "7       2       0.000001          64        0.883070  0.893847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "192/192 - 11s - loss: 0.3321 - accuracy: 0.8638 - val_loss: 0.1366 - val_accuracy: 0.9577 - 11s/epoch - 59ms/step\n",
            "Epoch 2/3\n",
            "192/192 - 7s - loss: 0.0980 - accuracy: 0.9692 - val_loss: 0.0551 - val_accuracy: 0.9779 - 7s/epoch - 38ms/step\n",
            "Epoch 3/3\n",
            "192/192 - 7s - loss: 0.0432 - accuracy: 0.9859 - val_loss: 0.0458 - val_accuracy: 0.9882 - 7s/epoch - 38ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-06, Batch Size: 64, Validation MCC: 0.968306771753793, Test MCC: 0.969368062742588\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n",
            "2       3       0.000001          16        0.838531  0.841273\n",
            "3       1       0.000001          32        0.914917  0.942097\n",
            "4       2       0.000001          32        0.761156  0.796942\n",
            "5       3       0.000001          32        0.958125  0.964260\n",
            "6       1       0.000001          64        0.940491  0.945728\n",
            "7       2       0.000001          64        0.883070  0.893847\n",
            "8       3       0.000001          64        0.968307  0.969368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 - 23s - loss: 0.3310 - accuracy: 0.8747 - val_loss: 0.6640 - val_accuracy: 0.8255 - 23s/epoch - 30ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-05, Batch Size: 16, Validation MCC: 0.4925168268198141, Test MCC: 0.5034196369006494\n",
            "   Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0       1       0.000001          16        0.000000  0.000000\n",
            "1       2       0.000001          16        0.892703  0.892049\n",
            "2       3       0.000001          16        0.838531  0.841273\n",
            "3       1       0.000001          32        0.914917  0.942097\n",
            "4       2       0.000001          32        0.761156  0.796942\n",
            "5       3       0.000001          32        0.958125  0.964260\n",
            "6       1       0.000001          64        0.940491  0.945728\n",
            "7       2       0.000001          64        0.883070  0.893847\n",
            "8       3       0.000001          64        0.968307  0.969368\n",
            "9       1       0.000010          16        0.492517  0.503420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "766/766 - 22s - loss: 0.3792 - accuracy: 0.8592 - val_loss: 0.5894 - val_accuracy: 0.7509 - 22s/epoch - 29ms/step\n",
            "Epoch 2/2\n",
            "766/766 - 18s - loss: 0.5708 - accuracy: 0.7501 - val_loss: 0.5621 - val_accuracy: 0.7509 - 18s/epoch - 24ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-05, Batch Size: 16, Validation MCC: 0.0, Test MCC: 0.0\n",
            "    Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0        1       0.000001          16        0.000000  0.000000\n",
            "1        2       0.000001          16        0.892703  0.892049\n",
            "2        3       0.000001          16        0.838531  0.841273\n",
            "3        1       0.000001          32        0.914917  0.942097\n",
            "4        2       0.000001          32        0.761156  0.796942\n",
            "5        3       0.000001          32        0.958125  0.964260\n",
            "6        1       0.000001          64        0.940491  0.945728\n",
            "7        2       0.000001          64        0.883070  0.893847\n",
            "8        3       0.000001          64        0.968307  0.969368\n",
            "9        1       0.000010          16        0.492517  0.503420\n",
            "10       2       0.000010          16        0.000000  0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "766/766 - 22s - loss: 0.2811 - accuracy: 0.9028 - val_loss: 0.1615 - val_accuracy: 0.9383 - 22s/epoch - 29ms/step\n",
            "Epoch 2/3\n",
            "766/766 - 18s - loss: 0.3385 - accuracy: 0.8980 - val_loss: 0.2756 - val_accuracy: 0.9219 - 18s/epoch - 24ms/step\n",
            "Epoch 3/3\n",
            "766/766 - 18s - loss: 0.2891 - accuracy: 0.9094 - val_loss: 0.2989 - val_accuracy: 0.9448 - 18s/epoch - 24ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-05, Batch Size: 16, Validation MCC: 0.8539363581796552, Test MCC: 0.8658423624117166\n",
            "    Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0        1       0.000001          16        0.000000  0.000000\n",
            "1        2       0.000001          16        0.892703  0.892049\n",
            "2        3       0.000001          16        0.838531  0.841273\n",
            "3        1       0.000001          32        0.914917  0.942097\n",
            "4        2       0.000001          32        0.761156  0.796942\n",
            "5        3       0.000001          32        0.958125  0.964260\n",
            "6        1       0.000001          64        0.940491  0.945728\n",
            "7        2       0.000001          64        0.883070  0.893847\n",
            "8        3       0.000001          64        0.968307  0.969368\n",
            "9        1       0.000010          16        0.492517  0.503420\n",
            "10       2       0.000010          16        0.000000  0.000000\n",
            "11       3       0.000010          16        0.853936  0.865842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 - 15s - loss: 0.2075 - accuracy: 0.9201 - val_loss: 0.1088 - val_accuracy: 0.9512 - 15s/epoch - 39ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-05, Batch Size: 32, Validation MCC: 0.8672133970751952, Test MCC: 0.8959286257908466\n",
            "    Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0        1       0.000001          16        0.000000  0.000000\n",
            "1        2       0.000001          16        0.892703  0.892049\n",
            "2        3       0.000001          16        0.838531  0.841273\n",
            "3        1       0.000001          32        0.914917  0.942097\n",
            "4        2       0.000001          32        0.761156  0.796942\n",
            "5        3       0.000001          32        0.958125  0.964260\n",
            "6        1       0.000001          64        0.940491  0.945728\n",
            "7        2       0.000001          64        0.883070  0.893847\n",
            "8        3       0.000001          64        0.968307  0.969368\n",
            "9        1       0.000010          16        0.492517  0.503420\n",
            "10       2       0.000010          16        0.000000  0.000000\n",
            "11       3       0.000010          16        0.853936  0.865842\n",
            "12       1       0.000010          32        0.867213  0.895929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "383/383 - 16s - loss: 0.2256 - accuracy: 0.9090 - val_loss: 0.1315 - val_accuracy: 0.9509 - 16s/epoch - 41ms/step\n",
            "Epoch 2/2\n",
            "383/383 - 11s - loss: 0.0684 - accuracy: 0.9772 - val_loss: 0.0513 - val_accuracy: 0.9870 - 11s/epoch - 29ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-05, Batch Size: 32, Validation MCC: 0.9652259775369204, Test MCC: 0.9724511194986362\n",
            "    Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0        1       0.000001          16        0.000000  0.000000\n",
            "1        2       0.000001          16        0.892703  0.892049\n",
            "2        3       0.000001          16        0.838531  0.841273\n",
            "3        1       0.000001          32        0.914917  0.942097\n",
            "4        2       0.000001          32        0.761156  0.796942\n",
            "5        3       0.000001          32        0.958125  0.964260\n",
            "6        1       0.000001          64        0.940491  0.945728\n",
            "7        2       0.000001          64        0.883070  0.893847\n",
            "8        3       0.000001          64        0.968307  0.969368\n",
            "9        1       0.000010          16        0.492517  0.503420\n",
            "10       2       0.000010          16        0.000000  0.000000\n",
            "11       3       0.000010          16        0.853936  0.865842\n",
            "12       1       0.000010          32        0.867213  0.895929\n",
            "13       2       0.000010          32        0.965226  0.972451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "383/383 - 16s - loss: 0.4305 - accuracy: 0.8764 - val_loss: 0.2084 - val_accuracy: 0.9196 - 16s/epoch - 41ms/step\n",
            "Epoch 2/3\n",
            "383/383 - 12s - loss: 0.1198 - accuracy: 0.9602 - val_loss: 0.1322 - val_accuracy: 0.9478 - 12s/epoch - 30ms/step\n",
            "Epoch 3/3\n",
            "383/383 - 11s - loss: 0.0586 - accuracy: 0.9802 - val_loss: 0.0453 - val_accuracy: 0.9878 - 11s/epoch - 28ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-05, Batch Size: 32, Validation MCC: 0.9672824593725099, Test MCC: 0.9806372314171686\n",
            "    Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0        1       0.000001          16        0.000000  0.000000\n",
            "1        2       0.000001          16        0.892703  0.892049\n",
            "2        3       0.000001          16        0.838531  0.841273\n",
            "3        1       0.000001          32        0.914917  0.942097\n",
            "4        2       0.000001          32        0.761156  0.796942\n",
            "5        3       0.000001          32        0.958125  0.964260\n",
            "6        1       0.000001          64        0.940491  0.945728\n",
            "7        2       0.000001          64        0.883070  0.893847\n",
            "8        3       0.000001          64        0.968307  0.969368\n",
            "9        1       0.000010          16        0.492517  0.503420\n",
            "10       2       0.000010          16        0.000000  0.000000\n",
            "11       3       0.000010          16        0.853936  0.865842\n",
            "12       1       0.000010          32        0.867213  0.895929\n",
            "13       2       0.000010          32        0.965226  0.972451\n",
            "14       3       0.000010          32        0.967282  0.980637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192/192 - 11s - loss: 0.5124 - accuracy: 0.7837 - val_loss: 0.1667 - val_accuracy: 0.9406 - 11s/epoch - 58ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 1, Learning Rate: 1e-05, Batch Size: 64, Validation MCC: 0.8377252407155293, Test MCC: 0.8448265360382851\n",
            "    Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0        1       0.000001          16        0.000000  0.000000\n",
            "1        2       0.000001          16        0.892703  0.892049\n",
            "2        3       0.000001          16        0.838531  0.841273\n",
            "3        1       0.000001          32        0.914917  0.942097\n",
            "4        2       0.000001          32        0.761156  0.796942\n",
            "5        3       0.000001          32        0.958125  0.964260\n",
            "6        1       0.000001          64        0.940491  0.945728\n",
            "7        2       0.000001          64        0.883070  0.893847\n",
            "8        3       0.000001          64        0.968307  0.969368\n",
            "9        1       0.000010          16        0.492517  0.503420\n",
            "10       2       0.000010          16        0.000000  0.000000\n",
            "11       3       0.000010          16        0.853936  0.865842\n",
            "12       1       0.000010          32        0.867213  0.895929\n",
            "13       2       0.000010          32        0.965226  0.972451\n",
            "14       3       0.000010          32        0.967282  0.980637\n",
            "15       1       0.000010          64        0.837725  0.844827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "192/192 - 12s - loss: 0.3912 - accuracy: 0.8396 - val_loss: 0.1315 - val_accuracy: 0.9501 - 12s/epoch - 64ms/step\n",
            "Epoch 2/2\n",
            "192/192 - 7s - loss: 0.0931 - accuracy: 0.9695 - val_loss: 0.0479 - val_accuracy: 0.9832 - 7s/epoch - 38ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 2, Learning Rate: 1e-05, Batch Size: 64, Validation MCC: 0.9559314784473741, Test MCC: 0.9544506961759793\n",
            "    Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0        1       0.000001          16        0.000000  0.000000\n",
            "1        2       0.000001          16        0.892703  0.892049\n",
            "2        3       0.000001          16        0.838531  0.841273\n",
            "3        1       0.000001          32        0.914917  0.942097\n",
            "4        2       0.000001          32        0.761156  0.796942\n",
            "5        3       0.000001          32        0.958125  0.964260\n",
            "6        1       0.000001          64        0.940491  0.945728\n",
            "7        2       0.000001          64        0.883070  0.893847\n",
            "8        3       0.000001          64        0.968307  0.969368\n",
            "9        1       0.000010          16        0.492517  0.503420\n",
            "10       2       0.000010          16        0.000000  0.000000\n",
            "11       3       0.000010          16        0.853936  0.865842\n",
            "12       1       0.000010          32        0.867213  0.895929\n",
            "13       2       0.000010          32        0.965226  0.972451\n",
            "14       3       0.000010          32        0.967282  0.980637\n",
            "15       1       0.000010          64        0.837725  0.844827\n",
            "16       2       0.000010          64        0.955931  0.954451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "192/192 - 11s - loss: 0.2736 - accuracy: 0.8842 - val_loss: 0.1657 - val_accuracy: 0.9364 - 11s/epoch - 58ms/step\n",
            "Epoch 2/3\n",
            "192/192 - 7s - loss: 0.0783 - accuracy: 0.9726 - val_loss: 0.0604 - val_accuracy: 0.9787 - 7s/epoch - 38ms/step\n",
            "Epoch 3/3\n",
            "192/192 - 7s - loss: 0.1381 - accuracy: 0.9494 - val_loss: 0.0400 - val_accuracy: 0.9882 - 7s/epoch - 37ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Epochs: 3, Learning Rate: 1e-05, Batch Size: 64, Validation MCC: 0.968347162061458, Test MCC: 0.9786766620349963\n",
            "    Epochs  Learning Rate  Batch Size  Validation MCC  Test MCC\n",
            "0        1       0.000001          16        0.000000  0.000000\n",
            "1        2       0.000001          16        0.892703  0.892049\n",
            "2        3       0.000001          16        0.838531  0.841273\n",
            "3        1       0.000001          32        0.914917  0.942097\n",
            "4        2       0.000001          32        0.761156  0.796942\n",
            "5        3       0.000001          32        0.958125  0.964260\n",
            "6        1       0.000001          64        0.940491  0.945728\n",
            "7        2       0.000001          64        0.883070  0.893847\n",
            "8        3       0.000001          64        0.968307  0.969368\n",
            "9        1       0.000010          16        0.492517  0.503420\n",
            "10       2       0.000010          16        0.000000  0.000000\n",
            "11       3       0.000010          16        0.853936  0.865842\n",
            "12       1       0.000010          32        0.867213  0.895929\n",
            "13       2       0.000010          32        0.965226  0.972451\n",
            "14       3       0.000010          32        0.967282  0.980637\n",
            "15       1       0.000010          64        0.837725  0.844827\n",
            "16       2       0.000010          64        0.955931  0.954451\n",
            "17       3       0.000010          64        0.968347  0.978677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HP\n",
        "\n",
        "learning_rate  = 1e-5\n",
        "batch_size = 32\n",
        "nb_epochs = 10"
      ],
      "metadata": {
        "id": "swIS4m6NGqzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_net = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(32, 32, 3))"
      ],
      "metadata": {
        "id": "wspWjE_uOA8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_net.trainable = True\n",
        "model = Sequential()     #Starting Point\n",
        "model.add(vgg16_net)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256)) # using 128 for a moderate size for a dense layer, enough capacity for meaningfull pattern, and to not increase the risk of overfitting # 256\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "metadata": {
        "id": "EzhlVydYOGHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=learning_rate), # keep a small learning rate, because the model's weight are already very well tuned and we need only very small adaptation to tune our model\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1QmB8ECOJWP",
        "outputId": "51522510-2f5a-4156-8edd-68d78cb5d03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nb_epoch = 5\n",
        "model.fit(train_images, train_labels,\n",
        "              batch_size=batch_size,\n",
        "              epochs=nb_epochs,\n",
        "              validation_data = val_dataset,\n",
        "              shuffle=True,\n",
        "              verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vgCFCWxOQ0I",
        "outputId": "b83c571d-e92e-4efb-8f78-d30a86817953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "383/383 - 16s - loss: 0.2221 - accuracy: 0.9169 - val_loss: 0.0697 - val_accuracy: 0.9737 - 16s/epoch - 43ms/step\n",
            "Epoch 2/10\n",
            "383/383 - 11s - loss: 0.0774 - accuracy: 0.9744 - val_loss: 0.0422 - val_accuracy: 0.9901 - 11s/epoch - 28ms/step\n",
            "Epoch 3/10\n",
            "383/383 - 11s - loss: 0.0641 - accuracy: 0.9798 - val_loss: 0.1041 - val_accuracy: 0.9611 - 11s/epoch - 28ms/step\n",
            "Epoch 4/10\n",
            "383/383 - 10s - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.1055 - val_accuracy: 0.9615 - 10s/epoch - 27ms/step\n",
            "Epoch 5/10\n",
            "383/383 - 11s - loss: 0.3103 - accuracy: 0.8886 - val_loss: 0.0940 - val_accuracy: 0.9730 - 11s/epoch - 28ms/step\n",
            "Epoch 6/10\n",
            "383/383 - 11s - loss: 0.1267 - accuracy: 0.9555 - val_loss: 0.1156 - val_accuracy: 0.9570 - 11s/epoch - 28ms/step\n",
            "Epoch 7/10\n",
            "383/383 - 11s - loss: 0.0770 - accuracy: 0.9748 - val_loss: 0.0528 - val_accuracy: 0.9810 - 11s/epoch - 28ms/step\n",
            "Epoch 8/10\n",
            "383/383 - 11s - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.0377 - val_accuracy: 0.9890 - 11s/epoch - 28ms/step\n",
            "Epoch 9/10\n",
            "383/383 - 11s - loss: 0.1006 - accuracy: 0.9676 - val_loss: 0.0416 - val_accuracy: 0.9851 - 11s/epoch - 28ms/step\n",
            "Epoch 10/10\n",
            "383/383 - 11s - loss: 0.0291 - accuracy: 0.9909 - val_loss: 0.0465 - val_accuracy: 0.9836 - 11s/epoch - 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c16c24efb80>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(test_images)\n",
        "print(\"Size of the testing set:\", len(test_images))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB4HhPr8OVZA",
        "outputId": "188e9c3e-be19-40e6-9660-ff959d1212f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 1s 8ms/step\n",
            "Size of the testing set: 2625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions"
      ],
      "metadata": {
        "id": "1rQpCnrrcCW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77444b3-ce2b-4f8e-80dd-48b2684142da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9999987 ],\n",
              "       [1.        ],\n",
              "       [0.99999964],\n",
              "       ...,\n",
              "       [1.        ],\n",
              "       [0.99993527],\n",
              "       [1.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "# Assuming test_labels is your list or array of true labels for the test dataset\n",
        "# You may need to reshape or adjust dimensions to align with test_predictions\n",
        "\n",
        "# Flatten predictions to align with the labels\n",
        "test_predictions_flat = test_predictions.flatten()\n",
        "\n",
        "# Create a DataFrame to store predictions and ground truths\n",
        "df_test = pd.DataFrame({\n",
        "    'Predicted Probability': test_predictions_flat,\n",
        "    'Ground Truth': test_labels  # Ensure test_labels are correctly aligned and formatted\n",
        "})\n",
        "print(len(df_test['Predicted Probability'])\n",
        "          )\n",
        "# Example metrics calculation\n",
        "accuracy = accuracy_score(test_labels, test_predictions_flat > 0.5)  # Using 0.5 as threshold for binary classification\n",
        "precision = precision_score(test_labels, test_predictions_flat > 0.5)\n",
        "recall = recall_score(test_labels, test_predictions_flat > 0.5)\n",
        "f1 = f1_score(test_labels, test_predictions_flat > 0.5)\n",
        "roc_auc = roc_auc_score(test_labels, test_predictions_flat)  # AUC score\n",
        "mcc = matthews_corrcoef(test_labels, test_predictions_flat > 0.5)  # Matthew's Correlation Coefficient\n",
        "\n",
        "\n",
        "# Output metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "print(f\"Matthew's Correlation Coefficient: {mcc}\")\n",
        "\n",
        "\n",
        "\n",
        "# classfication report of scikit learn\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lc_RZlx4g2BH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04bb17d-1126-4e52-880e-268396668a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2625\n",
            "Accuracy: 0.9889523809523809\n",
            "Precision: 0.9899040888440181\n",
            "Recall: 0.9954314720812183\n",
            "F1 Score: 0.9926600860541634\n",
            "ROC AUC Score: 0.9995179602433448\n",
            "Matthew's Correlation Coefficient: 0.9703973506944035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is Recall?\n",
        "The recall, also named sensivity, or hit rate, tells us the fraction of correctly identified positive predictions.\n",
        "\n",
        "What fraction of the True predictions were actually True?This number should be as high as possible.\n",
        "\n",
        "High recall: Predicted most True values correctly.\n",
        "\n",
        "What is the f1-score?\n",
        "The f1-score, or F measure, measures precision and recall at the same time by finding the harmonic mean of the two values.\n",
        "\n",
        "This score is usefull when you have opposite scores coming from precision and recall\n",
        "\n",
        "The accuracy measures the accuracy of all predictions (positive and negative).\n",
        "\n",
        "Accuracy should be as high as possible."
      ],
      "metadata": {
        "id": "KMlOcikrvxSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_labels, test_predictions_flat > 0.5 ))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObLFo3PLksD1",
        "outputId": "30ab977d-3cc9-4280-c608-23351fa72fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       655\n",
            "           1       0.99      0.99      0.99      1970\n",
            "\n",
            "    accuracy                           0.99      2625\n",
            "   macro avg       0.99      0.99      0.99      2625\n",
            "weighted avg       0.99      0.99      0.99      2625\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_predictions = model.predict(val_images)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "# Flatten predictions to match the format of labels\n",
        "val_predictions_flat = val_predictions.flatten()\n",
        "\n",
        "# Assuming val_labels is your list or array of true labels for the validation dataset\n",
        "# Ensure val_labels are correctly aligned and formatted\n",
        "\n",
        "# Create a DataFrame to store predictions and ground truths\n",
        "df_valid = pd.DataFrame({\n",
        "    'Predicted Probability': val_predictions_flat,\n",
        "    'Ground Truth': val_labels  # Ensure val_labels are correctly aligned and formatted\n",
        "})\n",
        "\n",
        "# Threshold the probabilities at 0.5 to get binary class predictions\n",
        "binary_predictions = val_predictions_flat > 0.5\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(val_labels, binary_predictions)\n",
        "precision = precision_score(val_labels, binary_predictions)\n",
        "recall = recall_score(val_labels, binary_predictions)\n",
        "f1 = f1_score(val_labels, binary_predictions)\n",
        "roc_auc = roc_auc_score(val_labels, val_predictions_flat)\n",
        "mcc = matthews_corrcoef(val_labels, binary_predictions)  # Matthew's Correlation Coefficient\n",
        "\n",
        "# Output metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "print(f\"Matthew's Correlation Coefficient: {mcc}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bKi1GBooswg",
        "outputId": "430e1d1d-aa92-4df2-dab7-f2a8edfb2f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 1s 7ms/step\n",
            "Accuracy: 0.985904761904762\n",
            "Precision: 0.9888776541961577\n",
            "Recall: 0.9923896499238964\n",
            "F1 Score: 0.9906305393770575\n",
            "ROC AUC Score: 0.9981451226267111\n",
            "Matthew's Correlation Coefficient: 0.962215854637755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val_labels, binary_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shKqY8gVqAvq",
        "outputId": "21e6d952-db76-43fd-d733-0ec4c546c209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       654\n",
            "           1       0.99      0.99      0.99      1971\n",
            "\n",
            "    accuracy                           0.99      2625\n",
            "   macro avg       0.98      0.98      0.98      2625\n",
            "weighted avg       0.99      0.99      0.99      2625\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "# If you specifically want to print out the total, trainable, and non-trainable parameter counts:\n",
        "total_params = model.count_params()\n",
        "trainable_params = np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "non_trainable_params = np.sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])\n",
        "\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")\n",
        "print(f\"Non-trainable parameters: {non_trainable_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNzS-B0iYHSl",
        "outputId": "29a2347d-9b9a-430d-e1a2-9b4a06f97835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14780481 (56.38 MB)\n",
            "Trainable params: 14780481 (56.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Total parameters: 14780481\n",
            "Trainable parameters: 14780481\n",
            "Non-trainable parameters: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 & 1E-06 & 16 & - \\\\ \\hline\n",
        "# 1 & 1E-06 & 32 & - \\\\ \\hline\n",
        "# 1 & 1E-06 & 64 & - \\\\ \\hline\n",
        "# 1 & 1E-05 & 16 & - \\\\ \\hline\n",
        "# 1 & 1E-05 & 32 & - \\\\ \\hline\n",
        "# 1 & 1E-05 & 64 & - \\\\ \\hline\n",
        "# 2 & 1E-06 & 16 & - \\\\ \\hline\n",
        "# 2 & 1E-06 & 32 & - \\\\ \\hline\n",
        "# 2 & 1E-06 & 64 & - \\\\ \\hline\n",
        "# 2 & 1E-05 & 16 & - \\\\ \\hline\n",
        "# 2 & 1E-05 & 32 & - \\\\ \\hline\n",
        "# 2 & 1E-05 & 64 & - \\\\ \\hline\n",
        "# 3 & 1E-06 & 16 & - \\\\ \\hline\n",
        "# 3 & 1E-06 & 32 & - \\\\ \\hline\n",
        "# 3 & 1E-06 & 64 & - \\\\ \\hline\n",
        "# 3 & 1E-05 & 16 & - \\\\ \\hline\n",
        "# 3 & 1E-05 & 32 & - \\\\ \\hline\n",
        "# 3 & 1E-05 & 64 & - \\\\ \\hline"
      ],
      "metadata": {
        "id": "Uzp7Lk1uT5rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Training Loss vs Training Accuracy without a line linking them\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['Training Accuracy'], df['Training Loss'], color='b')\n",
        "plt.title('Training Loss vs. Training Accuracy')\n",
        "plt.xlabel('Training Accuracy (%)')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "# Annotating each point with its epoch number\n",
        "for i, row in df.iterrows():\n",
        "    plt.annotate(f\"{row['Epoch']} epoch\", (row['Training Accuracy'], row['Training Loss']),\n",
        "                 textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "op08tQmGIPLp",
        "outputId": "68adf51b-58d3-44d3-d729-b426724083be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}